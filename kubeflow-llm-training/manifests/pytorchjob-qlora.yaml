apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: qwen3-30b-qlora-train
  labels:
    app: llm-training
spec:
  runPolicy:
    cleanPodPolicy: None
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            role: master
        spec:

          nodeSelector:
            kubernetes.io/arch: amd64
            nvidia.com/gpu.product: NVIDIA-H100
          tolerations:
            - key: nvidia.com/gpu
              operator: Exists
              effect: NoSchedule
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: nvidia.com/gpu.product
                        operator: In
                        values: ["NVIDIA-H100"]
          containers:
            - name: trainer
              image: nvcr.io/nvidia/pytorch:24.07-py3
              imagePullPolicy: IfNotPresent
              command: ["bash", "-lc"]
              args:
                - >-
                  pip install -U "transformers==4.*" "datasets==2.*" peft deepspeed accelerate langfuse bitsandbytes tensorboard &&
                  torchrun --nproc_per_node=8 --nnodes=2 --rdzv_backend=c10d
                  --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT
                  /workspace/train/run_qlora.py
                  --model_name_or_path Qwen/Qwen3-30B-A3B-Thinking-2507-FP8
                  --dataset_dir /mnt/datasets/processed
                  --output_dir /mnt/checkpoints/qwen3-30b-qlora
                  --per_device_train_batch_size 1
                  --gradient_accumulation_steps 8
                  --learning_rate 1e-4
                  --num_train_epochs 3
                  --max_seq_length 4096
                  --bf16 True
                  --qlora True
                  --deepspeed /workspace/train/configs/ds_qlora.json
                  --logging_steps 10
                  --save_steps 1000
                  --save_total_limit 5
              env:
                - name: NCCL_DEBUG
                  value: WARN
                - name: NCCL_IB_DISABLE
                  value: "0"
                - name: NCCL_P2P_DISABLE
                  value: "0"
                - name: HUGGING_FACE_HUB_TOKEN
                  valueFrom: { secretKeyRef: { name: hf-token, key: HUGGING_FACE_HUB_TOKEN } }
                - name: LANGFUSE_PUBLIC_KEY
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_PUBLIC_KEY } }
                - name: LANGFUSE_SECRET_KEY
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_SECRET_KEY } }
                - name: LANGFUSE_HOST
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_HOST } }
              resources:
                limits:
                  nvidia.com/gpu: 8
                  cpu: "16"
                  memory: 128Gi
                requests:
                  nvidia.com/gpu: 8
                  cpu: "8"
                  memory: 96Gi
              volumeMounts:
                - name: datasets
                  mountPath: /mnt/datasets
                - name: checkpoints
                  mountPath: /mnt/checkpoints
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: datasets
              persistentVolumeClaim:
                claimName: llm-datasets-pvc
            - name: checkpoints
              persistentVolumeClaim:
                claimName: llm-checkpoints-pvc
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 64Gi
    Worker:
      replicas: 1
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            role: worker
        spec:
          nodeSelector:
            kubernetes.io/arch: amd64
            nvidia.com/gpu.product: NVIDIA-H100
          tolerations:
            - key: nvidia.com/gpu
              operator: Exists
              effect: NoSchedule
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: nvidia.com/gpu.product
                        operator: In
                        values: ["NVIDIA-H100"]
          containers:
            - name: trainer
              image: nvcr.io/nvidia/pytorch:24.07-py3
              imagePullPolicy: IfNotPresent
              command: ["bash", "-lc"]
              args:
                - >-
                  pip install -U "transformers==4.*" "datasets==2.*" peft deepspeed accelerate langfuse bitsandbytes tensorboard &&
                  torchrun --nproc_per_node=8 --nnodes=2 --rdzv_backend=c10d
                  --rdzv_endpoint=$MASTER_ADDR:$MASTER_PORT
                  /workspace/train/run_qlora.py
                  --model_name_or_path Qwen/Qwen3-30B-A3B-Thinking-2507-FP8
                  --dataset_dir /mnt/datasets/processed
                  --output_dir /mnt/checkpoints/qwen3-30b-qlora
                  --per_device_train_batch_size 1
                  --gradient_accumulation_steps 8
                  --learning_rate 1e-4
                  --num_train_epochs 3
                  --max_seq_length 4096
                  --bf16 True
                  --qlora True
                  --deepspeed /workspace/train/configs/ds_qlora.json
                  --logging_steps 10
                  --save_steps 1000
                  --save_total_limit 5
              env:
                - name: NCCL_DEBUG
                  value: WARN
                - name: NCCL_IB_DISABLE
                  value: "0"
                - name: NCCL_P2P_DISABLE
                  value: "0"
                - name: HUGGING_FACE_HUB_TOKEN
                  valueFrom: { secretKeyRef: { name: hf-token, key: HUGGING_FACE_HUB_TOKEN } }
                - name: LANGFUSE_PUBLIC_KEY
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_PUBLIC_KEY } }
                - name: LANGFUSE_SECRET_KEY
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_SECRET_KEY } }
                - name: LANGFUSE_HOST
                  valueFrom: { secretKeyRef: { name: langfuse-secrets, key: LANGFUSE_HOST } }
              resources:
                limits:
                  nvidia.com/gpu: 8
                  cpu: "16"
                  memory: 128Gi
                requests:
                  nvidia.com/gpu: 8
                  cpu: "8"
                  memory: 96Gi
              volumeMounts:
                - name: datasets
                  mountPath: /mnt/datasets
                - name: checkpoints
                  mountPath: /mnt/checkpoints
                - name: dshm
                  mountPath: /dev/shm
          volumes:
            - name: datasets
              persistentVolumeClaim:
                claimName: llm-datasets-pvc
            - name: checkpoints
              persistentVolumeClaim:
                claimName: llm-checkpoints-pvc
            - name: dshm
              emptyDir:
                medium: Memory
                sizeLimit: 64Gi

